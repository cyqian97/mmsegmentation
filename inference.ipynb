{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b0cc0e-febc-4374-980f-45b20ac4efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jovyan/work/mmsegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4fa1fb-c801-4613-a704-5a15ca782459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor\n",
    "import mmcv\n",
    "\n",
    "config_file = 'pspnet_r50-d8_512x1024_40k_cityscapes.py'\n",
    "checkpoint_file = 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# test a single image and show the results\n",
    "img = 'demo/demo.png'  # or img = mmcv.imread(img), which will only load it once\n",
    "result = inference_segmentor(model, img)\n",
    "# visualize the results in a new window\n",
    "# model.show_result(img, result, show=True)\n",
    "# or save the visualization results to image files\n",
    "# you can change the opacity of the painted segmentation map in (0, 1].\n",
    "model.show_result(img, result, out_file='result.jpg', opacity=0.5)\n",
    "\n",
    "# # test a video and show the results\n",
    "# video = mmcv.VideoReader('video.mp4')\n",
    "# for frame in video:\n",
    "#    result = inference_segmentor(model, frame)\n",
    "#    model.show_result(frame, result, wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aedb931-8062-475d-99d6-0f91e0a64be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/home/jovyan/work/dataset/Cityscapes/all_demoVideo_kitti/stuttgart_00/image_0/000000.png'\n",
    "result = inference_segmentor(model, img)\n",
    "model.show_result(img, result, out_file='/home/jovyan/work/dataset/Cityscapes/all_demoVideo_kitti/stuttgart_00/image_0_semantic/000000.png', opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c79fba-cbde-46ee-8c2a-e79849183d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/home/jovyan/work/dataset/Cityscapes/all_demoVideo_kitti/stuttgart_00/image_0/000005.png'\n",
    "result = inference_segmentor(model, img)\n",
    "model.show_result(img, result, out_file='/home/jovyan/work/dataset/Cityscapes/all_demoVideo_kitti/stuttgart_00/image_0_semantic/000005.png', opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f75f01-f817-4faa-8824-f255244c3417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mmseg]",
   "language": "python",
   "name": "conda-env-mmseg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
